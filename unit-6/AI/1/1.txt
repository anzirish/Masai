1. What is Artificial Intelligence (AI)?
Artificial Intelligence (AI) is a branch of computer science that focuses on creating machines or systems capable of performing tasks that typically require human intelligence. These tasks include understanding natural language, recognizing images or speech, making decisions, and learning from data. AI is used in everyday applications like voice assistants such as Siri or Alexa, self-driving cars, spam email detection, and recommendation systems, enabling machines to perform complex tasks more efficiently than traditional software.

2. What are Large Language Models (LLMs) and how do they work?
Large Language Models (LLMs) are advanced AI systems designed to understand, generate, and manipulate human language. They are trained on massive text datasets, learning grammar, context, and patterns of language, which allows them to produce coherent and contextually appropriate text. LLMs work by first breaking text into smaller units called tokens, then predicting the next token based on the context of previous tokens. For example, if the prompt is “The sun rises in the,” the model predicts the next token as “east,” generating human-like text token by token.

3. Difference between Traditional AI and Generative AI
Traditional AI generally focuses on analyzing data, making predictions, or classifying information based on rules or statistical models. Examples include spam detection or recommendation systems. Generative AI, on the other hand, creates new content such as text, images, or code, using patterns it learned from large datasets. While traditional AI is more about processing and analyzing existing data, generative AI is capable of producing novel outputs that were not explicitly present in its training data.

4. Concept of “prompting” in LLMs and its importance
Prompting is the process of providing instructions or input to an LLM to guide its output. The way a prompt is phrased strongly influences the quality, relevance, and style of the model’s response. Clear, specific, and context-rich prompts generally result in more accurate and useful outputs. For example, asking “Explain quantum physics in simple words” will yield a basic explanation, whereas “Explain quantum physics for a PhD-level physics student” will produce a detailed and technical response. Effective prompting is therefore essential for harnessing the full potential of LLMs.

5. Role of “tokens” in a language model
Tokens are the basic units that a language model processes, often representing words, subwords, or characters. LLMs generate text one token at a time, predicting the next token based on the previous ones in context. The number of tokens affects the model’s input and output length and can determine the cost and feasibility of a request. For instance, the sentence “ChatGPT is amazing” might be broken into tokens like [Chat, GPT, is, amaz, ing]. Proper management of tokens is important to ensure that the model’s output is complete and coherent, especially for longer prompts or documents.

6. Limitations or risks of Generative AI like ChatGPT
Generative AI models like ChatGPT are powerful but have several limitations and risks. They may produce inaccurate or “hallucinated” information that sounds plausible but is false. Since they are trained on large datasets from the internet, they can also reflect biases or stereotypes present in that data. Privacy is another concern, as sensitive information might be inadvertently included in outputs. Over-reliance on AI can lead users to trust it blindly without verification. Additionally, token limits can restrict context in long conversations, and there is potential for misuse, such as generating spam, fake news, or malicious content. Therefore, while generative AI is highly useful, it must be used responsibly and outputs should be carefully evaluated.